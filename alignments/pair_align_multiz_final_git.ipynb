{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901463dd-72fc-470f-996a-815f31d3d305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "import glob\n",
    "from Bio import SeqRecord\n",
    "import pandas as pd\n",
    "#pip install genomicranges #this worked \n",
    "import genomicranges as gr\n",
    "from Bio.Seq import Seq\n",
    "#from Bio.SeqRecord import SeqRecord \n",
    "import pyranges as pr\n",
    "from Bio import pairwise2\n",
    "from Bio.SeqUtils import GC\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad927f92-0ab5-414a-9a15-a802e6dd5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "myPath = # PATH TO GITHUB FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e15bd-62f5-48c4-b2b2-dc5a49cf7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sbatch_file(filename): \n",
    "    \n",
    "    my_list = [\"#!/bin/bash\", \n",
    "               \"#SBATCH --job-name=all_bz\", \n",
    "               \"#SBATCH --nodes=1\",  \n",
    "               \"#SBATCH --ntasks=1\",                     \n",
    "               \"#SBATCH --cpus-per-task=10\",              \n",
    "               \"#SBATCH --mem=20gb\",                    \n",
    "               \"#SBATCH --partition=20\",                \n",
    "               \"##SBATCH --output all_bz-%j.out\",  \n",
    "               \"#SBATCH --mail-type=ALL\",               \n",
    "               \"#SBATCH --mail-user=hlharris@wi.mit.edu\"] \n",
    "    \n",
    "    with open(filename, \"w\") as file: \n",
    "        for item in my_list:\n",
    "            file.write(item + '\\n') \n",
    "    \n",
    "def calc_zeros(alignment): \n",
    "\n",
    "    #returns string with 0's in gaps in human sequence \n",
    "     \n",
    "    count = 0 \n",
    "    return [0 if base == \"-\" else (count := count + 1) for base in alignment[0]]\n",
    "\n",
    "def crop_alignment(start, end, alignment):\n",
    "\n",
    "    #crop alignment by start and end coordinates\n",
    "\n",
    "    zeros_seq = calc_zeros(alignment)\n",
    "    try:\n",
    "        ix_start = zeros_seq.index(start)\n",
    "        ix_end = zeros_seq.index(end)\n",
    "        cropped_alignment = alignment[:, ix_start:ix_end]\n",
    "        return cropped_alignment\n",
    "    except: \n",
    "        return None\n",
    "    \n",
    "\n",
    "def concat_alignment(gtf_file, alignment):\n",
    "\n",
    "    #concatenate alignment based on gtf file coordinates to extract particular sections\n",
    "\n",
    "\n",
    "    complete_align_type = MultipleSeqAlignment([]) \n",
    "    #add the groups to complete align: \n",
    "    for recordix in range(len(alignment)): \n",
    "        new_record = SeqRecord.SeqRecord(\"\") \n",
    "        new_record.id = alignment[recordix].id \n",
    "        new_record.seq = Seq(\"\") #added this \n",
    "\n",
    "        complete_align_type.append(new_record)\n",
    "    \n",
    "   # print(complete_align_type)\n",
    "    for index, row in gtf_file.iterrows():     \n",
    "        crop_align = crop_alignment(row[3], row[4], alignment)\n",
    "        #print(crop_align)\n",
    "        if crop_align is not None: \n",
    "            for recordix in range(len(crop_align)): \n",
    "                complete_align_type[recordix].seq += crop_align[recordix].seq #append additional sequence\n",
    "        \n",
    "    return complete_align_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99d130-0fb2-4f89-8054-f68befac2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make directory for each gene pair \n",
    "genes = [\"EIF1AX\", \"EIF1AY\", \"KDM5D\" , \"KDM5C\",\"UTY\", \"KDM6A\", \"ZFY\", \"ZFX\", \"DDX3Y\" ,\"DDX3X\", \"USP9Y\" , \"USP9X\", \"RPS4Y1\", \"RPS4X\"] \n",
    "\n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"],  \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1'], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"]}\n",
    "\n",
    "#extract human X and Y genes \n",
    "\n",
    "for gene_pair,two_genes in gene_pair_dict.items(): \n",
    "    subprocess.run(['mkdir', myPath + '/sequences/pair_align/' + gene_pair],  stderr=subprocess.PIPE) \n",
    "    records_X = list(SeqIO.parse(myPath + '/sequences/' + two_genes[0] + \".fa\", \"fasta\")) \n",
    "    SeqIO.write(records_X[0], myPath + '/sequences/pair_align/' + gene_pair + '/human_Xgene', 'fasta') \n",
    "\n",
    "    records_Y = list(SeqIO.parse(myPath + '/sequences/' + two_genes[1]  + \".fa\", \"fasta\")) \n",
    "    SeqIO.write(records_Y[0], myPath + '/sequences/pair_align/' + gene_pair + '/human_Ygene' , 'fasta') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959088c-159d-49c0-bdcf-b809fad0f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#align X-Y pair genes \n",
    "\n",
    "for gene_pair, two_genes in gene_pair_dict.items(): \n",
    "\n",
    "    tree = '(human_Xgene human_Ygene)'\n",
    "    \n",
    "    os.chdir(myPath + '/sequences/pair_align/'+ gene_pair)\n",
    "\n",
    "    subprocess.run([\"touch\", \"all_bz.log\"])  #making a new file \n",
    "    \n",
    "    with open(\"all_bz.log\", \"w\") as log_file:\n",
    "        result = subprocess.run(['all_bz', '-', tree], stdout=log_file, stderr=subprocess.PIPE, check=True)\n",
    "        \n",
    "    make_sbatch_file(\"testj1.sh\") #make sbatch file - it makes a new one each time through so you dont have to delete the old one \n",
    "    print(gene_pair) \n",
    "    with open(\"testj1.sh\", \"a\") as file: #append to the file \n",
    "        file.write(\"bash \") \n",
    "        file.write(\"all_bz.log\" + \"\\n\")\n",
    "        file.write(\"tba '\" + tree + \"' *.*.maf tba.maf >&tba.log\" + \"\\n\") \n",
    "        file.write(\"maf_project tba.maf human_Xgene '\" + tree + \"' > human_proj.maf\" + \"\\n\") #project from the perspective of the X chr \n",
    "        file.write(\"msa_view -o FASTA human_proj.maf > \" + gene_pair + \"_msa.fa\")\n",
    "        \n",
    "    subprocess.run([\"sbatch\", 'testj1.sh'], stderr=subprocess.PIPE) \n",
    "\n",
    "    os.chdir(myPath + '/sequences/pair_align/')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162651ac-61a3-411b-9d98-a9e60d0bc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write alignments as phylip files\n",
    "\n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"],  \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1'], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"]}\n",
    "\n",
    "for gene_pair, two_genes in gene_pair_dict.items():     \n",
    "    records = SeqIO.parse(myPath + \"/sequences/pair_align/\" +  gene_pair + \"/\" +  gene_pair +  \"_msa.fa\", \"fasta\") \n",
    "    new_name = myPath + \"/sequences/pair_align/\" +  gene_pair + \"/\" +  gene_pair + \"_msa.phy\"\n",
    "    SeqIO.write(records, new_name, 'phylip') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f990c70-1acd-483d-a46d-c22cae91423b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract regions\n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"], \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1']}\n",
    "\n",
    "regions = [\"promoter\", \"exon\", \"intron\"]   \n",
    "\n",
    "for gene_pair, two_genes in gene_pair_dict.items(): \n",
    "    alignment = AlignIO.read(myPath + \"/sequences/pair_align/\" + gene_pair + \"/\" + gene_pair + \"_msa.fa\", \"fasta\")\n",
    "    \n",
    "    gtf_file = pd.read_csv(myPath + \"/tables/\" + two_genes[0] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "    \n",
    "    for region in regions: \n",
    "        gtf_file1 = gtf_file[gtf_file[2] == region] \n",
    "        #print(gtf_file1)\n",
    "        returned_align = concat_alignment(gtf_file1,alignment) \n",
    "        #print(gene_pair, returned_align, region)\n",
    "        SeqIO.write(returned_align, myPath + \"/sequences/pair_align/\" + gene_pair + \"/\" + gene_pair + \"_\" + region + \"_msa.fa\", \"fasta\") #as fasta\n",
    "        SeqIO.write(returned_align, \"/sequences/pair_align/\" + gene_pair + \"/\" + gene_pair + \"_\" + region + \"_msa.phy\", \"phylip\") #as phylip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2715c-e6e6-4fca-9fc8-c2e8c20d39b8",
   "metadata": {},
   "source": [
    "After generating the homolog alignments: \n",
    "    \n",
    "    -use trimal to remove all gaps -- \n",
    "    -find the promoter %id \n",
    "    -find the exon %id \n",
    "    -find the intronic %id \n",
    "\n",
    "-leave the gaps in these alignments - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf36931d-8830-48d4-a405-846d7168e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_alignment(records_X, pair, region):\n",
    "\n",
    "    new_alignment = MultipleSeqAlignment([])\n",
    "    records_x_lost = [0,1] #take edit the alignment \n",
    "    \n",
    "    for ix in records_x_lost:\n",
    "        \n",
    "        new_record = records_X[ix]\n",
    "     \n",
    "        new_alignment.append(new_record)\n",
    "    \n",
    "  \n",
    "    SeqIO.write(new_alignment, myPath + \"/sequences/pair_align/\" + pair + \"/\" + \"human_XY_\" + region + \"_msa.phy\", \"phylip\") #as phylip\n",
    "    \n",
    "    #use trimal to get rid of regions with gaps in X and Y\n",
    "    #CHANGE TO YOUR TRIMAL LOCATION \n",
    "    subprocess.run(['/lab/page_scratch/hannah/trimal/source/trimal', '-in', myPath + \"/sequences/pair_align/\" + pair + \"/\" + \"human_XY_\" + region + \"_msa.phy\", '-out', myPath + '/sequences/pair_align/' + pair + '/' + 'human_XY' + '_' + region + '_msa_filtered.phy', '-noallgaps'],  stderr=subprocess.PIPE)\n",
    "\n",
    "    \n",
    "    \n",
    "    records_X = list(SeqIO.parse(myPath + '/sequences/pair_align/' + pair + '/' + 'human_XY' + '_' + region + '_msa_filtered.phy', \"phylip\"))\n",
    "    \n",
    "    \n",
    "    new_alignment = MultipleSeqAlignment([])\n",
    "    records_x_lost = [0,1] #take edit the alignment since now its only 2 sequences long\n",
    "    \n",
    "    for ix in records_x_lost:\n",
    "    # Replace '*' with '-' in the sequence so can remove them with trimal \n",
    "        \n",
    "        modified_seq  = str(records_X[ix].seq).replace('-', 'K')\n",
    "        modified_seq = str(modified_seq).replace('*', '-')\n",
    "        modified_seq = str(modified_seq).replace('K', '*') #replacing the - w stars - want to keep the gaps for the calculations of % alignments \n",
    "        new_record = records_X[ix]\n",
    "        new_record.seq = Seq(modified_seq)     \n",
    "        new_alignment.append(new_record)\n",
    "                \n",
    "\n",
    "    SeqIO.write(new_alignment, myPath + \"/sequences/pair_align/\" + pair + \"/\" + \"human_XY_\" + region + \"_msa.phy\", \"phylip\") #as phylip\n",
    "\n",
    "    subprocess.run(['/lab/page_scratch/hannah/trimal/source/trimal', '-in', myPath + '/sequences/pair_align/' + pair + '/' + 'human_XY' + '_' + region + '_msa.phy', '-out', myPath + '/sequences/pair_align/' + pair + '/' + 'human_XY' + '_' + region + '_msa_filtered.phy', '-gt', '1'],  stderr=subprocess.PIPE)\n",
    "        \n",
    "    try:\n",
    "        new_alignment = list(SeqIO.parse(myPath + '/sequences/pair_align/' + pair + '/' + 'human_XY' + '_' + region + '_msa_filtered.phy', \"phylip\"))    \n",
    "        return new_alignment\n",
    "          \n",
    "    except: \n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d1d5e-e21b-4a0b-8490-4bccf5d8e1c8",
   "metadata": {},
   "source": [
    "## calculate percent ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dd501dc-4a48-4496-9601-964fd00d1be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions = [\"exon\", \"intron\"]  \n",
    "pairs = [ \"EIF1AX_EIF1AY\",\"KDM5C_KDM5D\", \"KDM6A_UTY\", \"ZFX_ZFY\", \"DDX3X_DDX3Y\", \"USP9X_USP9Y\", \"RPS4X_RPS4Y1\"]\n",
    "\n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"], \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1']}\n",
    "\n",
    "regions = [\"intron\", \"exon\"]\n",
    "\n",
    "\n",
    "p = []\n",
    "r = []\n",
    "perc = []\n",
    "combos = set()\n",
    "combo_dict = {}\n",
    "\n",
    "for gp_d in gene_pair_dict: \n",
    "    pair = gp_d\n",
    "    #print(pair, region)\n",
    "    \n",
    "    for region in regions: \n",
    "              \n",
    "            records_X = list(SeqIO.parse(myPath + '/sequences/pair_align/' + pair + \"/\" + pair + \"_\" + region + \"_msa.fa\", \"fasta\")) \n",
    "          \n",
    "            new_alignment = edit_alignment(records_X, pair, region)\n",
    "           \n",
    "            if new_alignment:\n",
    "                x_gene = new_alignment[0] \n",
    "                y_gene = new_alignment[1] \n",
    "              # print(x_gene, y_gene)\n",
    "                num_matches = sum(a == b for a, b in zip(x_gene, y_gene))\n",
    "              # print(num_matches)\n",
    "              # print(len(x_gene))\n",
    "                percent_identity = (num_matches / len(x_gene)) * 100\n",
    "                p.append(pair)\n",
    "                r.append(region) \n",
    "                perc.append(percent_identity)\n",
    "            else: \n",
    "                print(pair, region, \"NONE\")\n",
    "                \n",
    "for pair1, genes1 in gene_pair_dict.items():\n",
    "    for pair2, genes2 in gene_pair_dict.items():\n",
    "        combos.add((genes1[0], genes2[1]))\n",
    "        combo_dict[(genes1[0], genes2[1])] = genes1[0] + \"_\" + genes2[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab0d77-e7b8-4939-89c2-c3cd3874bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((list(zip(p,r,perc))), columns = ['pair', 'region', 'percent']) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86cc083-aa03-415f-856a-c6235ad22fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate files of alignment %'s\n",
    "\n",
    "for combo in combos: \n",
    "    \n",
    "    promoter_percent = get_perc(combo, 'promoter')[0] \n",
    "  \n",
    "    p.append(combo_dict[combo])\n",
    "    r.append(\"promoter\")\n",
    "    perc.append(promoter_percent)\n",
    "    \n",
    "df = pd.DataFrame((list(zip(p,r,perc))), columns = ['pair', 'region', 'percent']) \n",
    "\n",
    "df.to_csv(myPath + 'percent_alignment_0129.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed03b3-1f2a-4dba-8e3d-d306a31a793d",
   "metadata": {},
   "source": [
    "## get GC content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491cb41-cea9-4d3d-8795-c0de6afe1233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"], \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1']}\n",
    "regions = [\"exon\", \"intron\"]   \n",
    "\n",
    "gene = []\n",
    "pairs = []\n",
    "reg = []\n",
    "GC_perc = []\n",
    "\n",
    "for gp_d, gl in gene_pair_dict.items(): \n",
    "    pair = gp_d\n",
    "    \n",
    "    prom, gc_xp, gc_yp, algn= get_perc(gl, 'promoter')\n",
    "    GC_perc.append(gc_xp) \n",
    "    reg.append('promoter')\n",
    "    pairs.append(pair)\n",
    "    gene.append('X_gene')\n",
    "    \n",
    "    GC_perc.append(gc_yp)\n",
    "    reg.append('promoter')\n",
    "    pairs.append(pair)\n",
    "    gene.append('Y_gene')\n",
    "    \n",
    "    for region in regions:   \n",
    "        \n",
    "        alignment_x = AlignIO.read(myPath + \"/sequences/pair_align/\" + pair + \"/\" + \"human_Xgene\", \"fasta\")\n",
    "\n",
    "        gtf_file_x = pd.read_csv(myPath + \"/tables/\" + gl[0] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "        gtf_file_x = gtf_file_x[gtf_file_x[2] == region] \n",
    "        returned_align_x = concat_alignment(gtf_file_x,alignment_x) \n",
    "            \n",
    "            \n",
    "        alignment_y = AlignIO.read(myPath + \"/sequences/pair_align/\" + pair + \"/\" + \"human_Ygene\", \"fasta\")\n",
    "\n",
    "        gtf_file_y = pd.read_csv(myPath + \"/tables/\" + gl[1] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "        gtf_file_y = gtf_file_y[gtf_file_y[2] == region] \n",
    "        returned_align_y = concat_alignment(gtf_file_y,alignment_y) \n",
    "    \n",
    "        GC_perc.append(GC(returned_align_x[0].seq))\n",
    "        reg.append(region)\n",
    "        pairs.append(pair)\n",
    "        gene.append('X_gene')\n",
    "        \n",
    "        GC_perc.append(GC(returned_align_y[0].seq))\n",
    "        reg.append(region)\n",
    "        pairs.append(pair)\n",
    "        gene.append('Y_gene')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4319ab5c-a20e-4771-b4cf-b0d1df731192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame((list(zip(gene,pairs,reg, GC_perc))), columns = ['gene', 'pairs', 'region', 'GC_perc']) \n",
    "df1.to_csv('GC_0129.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e8c86-68ca-45bd-8683-4e70e01ddad5",
   "metadata": {},
   "source": [
    "## calculate CpG for promoters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adae6d4d-d2a6-4ce7-9376-0834cdde6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perc_fornormCG(combo,region): \n",
    "\n",
    "    gtf_file_x = pd.read_csv(myPath + \"/tables/\" + combo[0] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "    gtf_file_x1 = gtf_file_x[gtf_file_x[2] == region] \n",
    "\n",
    "    gtf_file_y = pd.read_csv(myPath + \"/tables/\" + combo[1] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "    gtf_file_y1 = gtf_file_y[gtf_file_y[2] == region] \n",
    "             \n",
    "    rec_x = list(SeqIO.parse(myPath + '/sequences/pair_align/' + combo[0] + \"/human\", \"fasta\"))\n",
    "    rec_y = list(SeqIO.parse(myPath + '/sequences/pair_align/' + combo[1] + \"/human\", \"fasta\"))\n",
    "\n",
    "    promoter_x = rec_x[0].seq[gtf_file_x1.iloc[0,3]: gtf_file_x1.iloc[0,4]]\n",
    "    #print(promoter_x)\n",
    "    promoter_y = rec_y[0].seq[gtf_file_y1.iloc[0,3]: gtf_file_y1.iloc[0,4]]\n",
    "    return promoter_x, promoter_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6db2aba-a6f6-459a-9e8f-5819c55f00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = []\n",
    "pairs = []\n",
    "reg = []\n",
    "CpG_norm = []\n",
    "raw_cpGs = []\n",
    "\n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"], \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1']}\n",
    "\n",
    "for gp_d, gl in gene_pair_dict.items(): \n",
    "    pair = gp_d\n",
    "    p_x, p_y = get_perc_fornormCG(gl, \"promoter\")\n",
    "    \n",
    "    p_x_CpG = (p_x.count(\"CG\") * 500) / (p_x.count(\"C\") * p_x.count(\"G\"))\n",
    "    p_y_CpG = (p_y.count(\"CG\") * 500) / (p_y.count(\"C\") * p_y.count(\"G\"))\n",
    "\n",
    "    CpG_norm.append(p_x_CpG)\n",
    "    reg.append(\"promoter\")\n",
    "    pairs.append(pair)    \n",
    "    gene.append('X_gene')\n",
    "    raw_cpGs.append(p_x.count(\"CG\")/500 *100)\n",
    "    \n",
    "    CpG_norm.append(p_y_CpG)\n",
    "    reg.append(\"promoter\")\n",
    "    pairs.append(pair)    \n",
    "    gene.append('Y_gene')\n",
    "    raw_cpGs.append(p_y.count(\"CG\")/500 *100)\n",
    "\n",
    "df1 = pd.DataFrame((list(zip(gene,pairs,reg, CpG_norm, raw_cpGs))), columns = ['gene', 'pairs', 'region', 'CpG_norm', 'raw_cpGs']) \n",
    "df1.to_csv(myPath + '/tables/CpG_0129.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeafff5c-b512-47ab-a09f-fa9584f12018",
   "metadata": {
    "tags": []
   },
   "source": [
    "## generate alignment for x and y promoters (defined by gtf coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c4dbe-63fd-4add-bbea-b60e3a8ab28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perc(combo,region): \n",
    "\n",
    "    gtf_file_x = pd.read_csv(myPath + \"/tables/\" + combo[0] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "    gtf_file_x1 = gtf_file_x[gtf_file_x[2] == region] \n",
    "\n",
    "    gtf_file_y = pd.read_csv(myPath + \"/tables/\" + combo[1] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "    gtf_file_y1 = gtf_file_y[gtf_file_y[2] == region] \n",
    "             \n",
    "    rec_x = list(SeqIO.parse(myPath + '/sequences/primates/' + combo[0] + \"/human\", \"fasta\"))\n",
    "    rec_y = list(SeqIO.parse(myPath + '/sequences/primates/' + combo[1] + \"/human\", \"fasta\"))\n",
    "\n",
    "    promoter_x = rec_x[0].seq[gtf_file_x1.iloc[0,3]: gtf_file_x1.iloc[0,4]]\n",
    "  \n",
    "    promoter_y = rec_y[0].seq[gtf_file_y1.iloc[0,3]: gtf_file_y1.iloc[0,4]]\n",
    "   \n",
    "    \n",
    "    GC_x = GC(promoter_x)\n",
    "    GC_y = GC(promoter_y)\n",
    "\n",
    "    #generating promoter alignmetns \n",
    "    alignments = pairwise2.align.globalxx(promoter_x, promoter_y) \n",
    "   \n",
    "    \n",
    "    best_alignment = max(alignments, key=lambda alignment: alignment[2])\n",
    "   \n",
    "    #Get the aligned sequences from the best alignment\n",
    "    aligned_x, aligned_y, score, start, end = best_alignment\n",
    " \n",
    "    #Get the aligned sequences from the best alignment  \n",
    "    aligned_seq1 = aligned_x \n",
    "    aligned_seq2 = aligned_y\n",
    "\n",
    "    num_matches = sum(a == b for a, b in zip(aligned_seq1, aligned_seq2))\n",
    "\n",
    "    percent_identity = (num_matches / len(aligned_seq1)) * 100 \n",
    "\n",
    "    return percent_identity, GC_x, GC_y, best_alignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b2550-a940-49bc-8c25-700dc0f08442",
   "metadata": {
    "tags": []
   },
   "source": [
    "## rolling alignment of 50 bp from X perspective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505843c-0c42-45c0-9c0c-6e1307870302",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "\n",
    "\n",
    "p = []\n",
    "r = []\n",
    "perc = []\n",
    "end_nums = []\n",
    "start_nums = []\n",
    "\n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"], \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1']}\n",
    "\n",
    "for gp_d, gl in gene_pair_dict.items(): \n",
    "    print(gp_d)\n",
    "    promoter_percent, GC_x, GC_y, best_alignment = get_perc(gl,  'promoter') #different alignment method\n",
    "    #print(best_alignment)\n",
    "    best_alignment = [\n",
    "    Seq(best_alignment[0]), Seq(best_alignment[1])]\n",
    "    seq_records = [SeqRecord(seq) for seq in best_alignment]\n",
    "    alignment = MultipleSeqAlignment(seq_records)\n",
    "    \n",
    "   \n",
    "                                           \n",
    "    for num in range(1, 450, 1): #change from 25 to 1 and 475 to 499\n",
    "        end_num = num + 50\n",
    "        crop_align_best = crop_alignment(num,end_num, alignment)\n",
    "        print(crop_align_best[0])\n",
    "        aligned_seq1 = crop_align_best[0] \n",
    "        aligned_seq2 = crop_align_best[1]\n",
    "\n",
    "        num_matches = sum(a == b for a, b in zip(aligned_seq1, aligned_seq2))\n",
    "\n",
    "    \n",
    "        percent_identity = (num_matches / len(aligned_seq1)) * 100 \n",
    "    \n",
    "        p.append(gp_d)\n",
    "        r.append(\"promoter\")\n",
    "        perc.append(percent_identity)\n",
    "        end_nums.append(end_num)\n",
    "        start_nums.append(num)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "df = pd.DataFrame((list(zip(p,r,perc, end_nums, start_nums))), columns = ['pair', 'region', 'percent', \"end_nums\", \"start_nums\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0922b-a39e-47d9-adfd-aed1c91d9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "df.to_csv(myPath + '/tables/perc_rolling_0129.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb74bd-64b3-407e-a6b2-ea39a2b6f8be",
   "metadata": {},
   "source": [
    "## get GC content promoters (from X perspective) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18cad6-f74f-4efa-95a2-6ecb109abd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = []\n",
    "gc = []\n",
    "type_ofgene = []\n",
    "regions1 = []\n",
    "\n",
    "regions = [ \"promoter\"]  \n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"], \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1']}\n",
    "\n",
    "\n",
    "\n",
    "for gp, gl in gene_pair_dict.items(): \n",
    "            print(gp) \n",
    "            if gp == \"KDM5C_KDM5D\":\n",
    "                continue\n",
    "            records = AlignIO.read(myPath + \"/sequences/pair_align/\" + gp + \"/\" + \"human_XY_promoter_msa_filtered.phy\", \"phylip\")\n",
    "            human_seq = str(records[0].seq)\n",
    "            animal_seq = str(records[1].seq)\n",
    "            \n",
    "            h_gc = ((human_seq.count('G') + human_seq.count('C')) / (human_seq.count('G') + human_seq.count('C') + human_seq.count('A') + human_seq.count('T'))) *100\n",
    "            a_gc = ((animal_seq.count('G') + animal_seq.count('C')) / (animal_seq.count('G') + animal_seq.count('C') + animal_seq.count('A') + animal_seq.count('T'))) *100\n",
    "            \n",
    "            gc.append(h_gc)\n",
    "            g.append(gp)\n",
    "            type_ofgene.append('X_gene')\n",
    "            \n",
    "            gc.append(a_gc) \n",
    "            g.append(gp)\n",
    "            type_ofgene.append('Y_gene')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dfe752ef-8056-41c9-a72f-6634b770038d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame((list(zip(g, gc, type_ofgene))), columns = ['pair', 'gc', 'type']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff34dd-8dac-4c62-ba54-955687a821c6",
   "metadata": {},
   "source": [
    "## scrambled promoter controls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2082ffa7-2b09-4715-bf16-905a80e283ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perc_mixedp(combo,region): \n",
    "\n",
    "    gtf_file_x = pd.read_csv(myPath + \"/sequences/tables/\" + combo[0] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "    gtf_file_x1 = gtf_file_x[gtf_file_x[2] == region] \n",
    "\n",
    "    gtf_file_y = pd.read_csv(myPath + \"/sequences/tables/\" + combo[1] + \"_gtf_all103023.txt\", delimiter=\"\\t\", header = None) \n",
    "    gtf_file_y1 = gtf_file_y[gtf_file_y[2] == region] \n",
    "             \n",
    "    rec_x = list(SeqIO.parse(myPath + '/sequences/primates/' + combo[0] + \"/human\", \"fasta\"))\n",
    "    rec_y = list(SeqIO.parse(myPath + '/sequences/primates/' + combo[1] + \"/human\", \"fasta\"))\n",
    "\n",
    "    promoter_x = rec_x[0].seq[gtf_file_x1.iloc[0,3]: gtf_file_x1.iloc[0,4]]\n",
    "  \n",
    "    promoter_y = rec_y[0].seq[gtf_file_y1.iloc[0,3]: gtf_file_y1.iloc[0,4]]\n",
    "   \n",
    "    print(promoter_x)\n",
    "    promoter_x = ''.join(random.sample(list(promoter_x), len(promoter_x)))\n",
    "    print(promoter_x)\n",
    "    print(promoter_y)\n",
    "    promoter_y = ''.join(random.sample(list(promoter_y), len(promoter_y)))\n",
    "\n",
    "    alignments = pairwise2.align.globalxx(promoter_x, promoter_y) \n",
    "   \n",
    "    \n",
    "    best_alignment = max(alignments, key=lambda alignment: alignment[2])\n",
    "   \n",
    "    #Get the aligned sequences from the best alignment\n",
    "    aligned_x, aligned_y, score, start, end = best_alignment\n",
    " \n",
    "    #Get the aligned sequences from the best alignment  \n",
    "    aligned_seq1 = aligned_x \n",
    "    aligned_seq2 = aligned_y\n",
    "\n",
    "    num_matches = sum(a == b for a, b in zip(aligned_seq1, aligned_seq2))\n",
    "\n",
    "    percent_identity = (num_matches / len(aligned_seq1)) * 100 \n",
    "\n",
    "    return percent_identity, best_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5129ff-5fbc-4bd4-9241-a5695e789aea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = []\n",
    "r = []\n",
    "perc = []\n",
    "\n",
    "gene_pair_dict = {\"EIF1AX_EIF1AY\": [\"EIF1AX\", \"EIF1AY\"], \"KDM5C_KDM5D\":[\"KDM5C\", \"KDM5D\"], \"KDM6A_UTY\": [\"KDM6A\", \"UTY\"], \"ZFX_ZFY\": [\"ZFX\", \"ZFY\"], \"DDX3X_DDX3Y\": [\"DDX3X\", \"DDX3Y\"],\n",
    "                 \"USP9X_USP9Y\": [\"USP9X\", \"USP9Y\"], \"RPS4X_RPS4Y1\": ['RPS4X', 'RPS4Y1']}\n",
    "\n",
    "for gp, combo in gene_pair_dict.items(): \n",
    "    \n",
    "    promoter_percent = get_perc_mixedp(combo,  'promoter')[0] \n",
    "  \n",
    "    p.append(gp)\n",
    "    r.append(\"promoter\")\n",
    "    perc.append(promoter_percent)\n",
    "    \n",
    "df = pd.DataFrame((list(zip(p,r,perc))), columns = ['pair', 'region', 'percent']) \n",
    "print(df)\n",
    "df.to_csv(myPath + '/tables/percent_alignment_scramble.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
